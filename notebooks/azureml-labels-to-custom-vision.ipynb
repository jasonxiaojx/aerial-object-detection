{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Azure ML Labeling Tags to Custom Vision Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages if needed\n",
    "import sys\n",
    "!{sys.executable} -m pip install azure-cognitiveservices-vision-customvision\n",
    "!{sys.executable} -m pip install azureml-sdk\n",
    "!{sys.executable} -m pip install azureml-contrib-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, shutil\n",
    "import azureml.contrib.dataset\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "\n",
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "# azureml-contrib-dataset of version 1.0.72 or higher is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up Custom Vision project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the details for your Custom Vision endpoint and training key below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://YOUR_REGION.api.cognitive.microsoft.com'\n",
    "training_key = \"<CUSTOM VISION TRAINING KEY>\"\n",
    "\n",
    "trainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Create new project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will create a new Custom Vision project.  Enter a name for your project below:\n",
    "\n",
    "Note: If you have an existing project, skip to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"<PROJECT NAME>\"\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print(\"Creating new project...\")\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)\n",
    "print(project.name, \"project created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Update existing Custom Vision project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will get an existing project by ID.  Enter your project ID below (you can retrieve this ID from your project in the [Custom Vision portal](http://customvision.ai)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<PROJECT ID>\"\n",
    "\n",
    "# Get existing project\n",
    "project = trainer.get_project(project_id = project_id) \n",
    "print(project.name, \"project retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get labeled dataset from Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labeling images with Azure Machine Learning, you can export the tags as an *Azure ML Dataset*:\n",
    "\n",
    "<img align=\"left\" src=\"../assets/aml_label_export.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the resulting dataset name from your *Datasets* in Azure Machine Learning Studio, and enter it below.  Similarly, enter the details for your subscription, resource group, and workspace.  You can also retrieve your Azure ML workspace through a [workspace config.json file](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '<SUBSCRIPTION ID>'\n",
    "resource_group = '<RESOURCE GROUP>'\n",
    "workspace_name = '<AML WORKSPACE NAME>'\n",
    "dataset_name = '<LABELED DATASET NAME>'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download images and parse labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've downloaded the image locations and associated label information into a dataframe `df` and need to download the actual images into a temporary directory by parsing the image details.  The downloaded Azure ML Dataset gives us a `StreamInfo` object that we need to parse to get the (1) datastore name and (2) image paths within the datastore. \n",
    "\n",
    "Note: The below code sample converts the `StreamInfo` object into a string and parses it through string operations.  This logic should be changed to access the `StreamInfo` properties directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to extract datastore name - no documentation on how to parse StreamInfo - TODO: parse StreamInfo correctly\n",
    "s = str(df.iloc[0].image_url) \n",
    "s = s.split('[')[1].split(']')[0]\n",
    "s = s.replace(\"'\", \"\\\"\") \n",
    "ds = json.loads(s)['datastoreName']\n",
    "\n",
    "# get datastore\n",
    "blob_datastore = Datastore.get(ws, ds)\n",
    "\n",
    "# create temp directory for labeled dataset download\n",
    "tmp_dir = '../tmp'\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "# hack to extract path - no documentation on how to parse StreamInfo - TODO: parse StreamInfo correctly\n",
    "df['path_to_download'] = df['image_url'].apply(lambda x: str(x).split('//')[1].split(\"[\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep images and format tags for Custom Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_ims = []\n",
    "tags = trainer.get_tags(project.id)\n",
    "\n",
    "for i, img in df.iterrows():\n",
    "    prefix = img['path_to_download']\n",
    "    blob_datastore.download(target_path=tmp_dir, prefix=prefix)\n",
    "    filename = os.path.join(tmp_dir,prefix)\n",
    "    \n",
    "    labels = img['label']\n",
    "    regions = []\n",
    "    \n",
    "    # parse labels\n",
    "    for label in labels:\n",
    "        label_name = label['label']\n",
    "\n",
    "        l = label['topX']\n",
    "        t = label['topY']\n",
    "        r = label['bottomX']\n",
    "        b = label['bottomY']\n",
    "\n",
    "        w = r-l\n",
    "        h = b-t\n",
    "        \n",
    "        # retrieve tag object by label name\n",
    "        try:\n",
    "            index = [x.name for x in tags].index(label_name)\n",
    "            tag = tags[index]\n",
    "        # create tag if it does not exist yet\n",
    "        except:\n",
    "            print(\"Creating new tag for:\", label_name)\n",
    "            tag = trainer.create_tag(project.id, label_name)\n",
    "            tags = trainer.get_tags(project.id)\n",
    "\n",
    "        # create bounding box regions\n",
    "        regions.append(Region(tag_id=tag.id,left=l,top=t,width=w,height=h))\n",
    "\n",
    "        with open(filename, mode=\"rb\") as im_data:\n",
    "            tagged_ims.append(ImageFileCreateEntry(name=filename, contents=im_data.read(), regions=regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload images and tags to Custom Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Uploading images and tags\")\n",
    "trainer.create_images_from_files(project.id, images=tagged_ims)\n",
    "\n",
    "# clean up temp directory\n",
    "shutil.rmtree(tmp_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
