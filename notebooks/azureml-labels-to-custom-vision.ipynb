{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Azure ML Labeling Tags to Custom Vision Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages if needed\n",
    "import sys\n",
    "!{sys.executable} -m pip install azure-cognitiveservices-vision-customvision\n",
    "!{sys.executable} -m pip install azureml-sdk\n",
    "!{sys.executable} -m pip install azureml-contrib-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, shutil, math\n",
    "\n",
    "import azureml.contrib.dataset\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azureml.contrib.dataset import FileHandlingOption\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "# azureml-contrib-dataset of version 1.0.72 or higher is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up Custom Vision project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the details for your Custom Vision endpoint and training key below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://YOUR_REGION.api.cognitive.microsoft.com'\n",
    "training_key = \"<CUSTOM VISION TRAINING KEY>\"\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(endpoint=ENDPOINT, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Create new project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will create a new Custom Vision project.  Enter a name for your project below:\n",
    "\n",
    "Note: If you have an existing project, skip to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new project...\n",
      "Sample project created\n"
     ]
    }
   ],
   "source": [
    "project_name = \"<PROJECT NAME>\"\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print(\"Creating new project...\")\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)\n",
    "print(project.name, \"project created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Update existing Custom Vision project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will get an existing project by ID.  Enter your project ID below (you can retrieve this ID from your project in the [Custom Vision portal](http://customvision.ai)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<PROJECT ID>\"\n",
    "\n",
    "# Get existing project\n",
    "project = trainer.get_project(project_id = project_id) \n",
    "print(project.name, \"project retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get labeled dataset from Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labeling images with Azure Machine Learning, you can export the tags as an *Azure ML Dataset*:\n",
    "\n",
    "<img align=\"left\" src=\"../assets/aml_label_export.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the resulting dataset name from your *Datasets* in Azure Machine Learning Studio, and enter it below.  Similarly, enter the details for your subscription, resource group, and workspace.  You can also retrieve your Azure ML workspace through a [workspace config.json file](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_url</th>\n",
       "      <th>label</th>\n",
       "      <th>label_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tmp/workspaceblobstore/UI/04-17-2020_033330_U...</td>\n",
       "      <td>[{'label': 'building', 'topX': 0.2188137755102...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tmp/workspaceblobstore/UI/04-17-2020_033330_U...</td>\n",
       "      <td>[{'label': 'vehicle', 'topX': 0.37935799319727...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tmp/workspaceblobstore/UI/04-17-2020_033330_U...</td>\n",
       "      <td>[{'label': 'vehicle', 'topX': 0.28434311224489...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_url  \\\n",
       "0  /tmp/workspaceblobstore/UI/04-17-2020_033330_U...   \n",
       "1  /tmp/workspaceblobstore/UI/04-17-2020_033330_U...   \n",
       "2  /tmp/workspaceblobstore/UI/04-17-2020_033330_U...   \n",
       "\n",
       "                                               label  \\\n",
       "0  [{'label': 'building', 'topX': 0.2188137755102...   \n",
       "1  [{'label': 'vehicle', 'topX': 0.37935799319727...   \n",
       "2  [{'label': 'vehicle', 'topX': 0.28434311224489...   \n",
       "\n",
       "                 label_confidence  \n",
       "0            [1.0, 1.0, 1.0, 1.0]  \n",
       "1       [1.0, 1.0, 1.0, 1.0, 1.0]  \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '<SUBSCRIPTION ID>'\n",
    "resource_group = '<RESOURCE GROUP>'\n",
    "workspace_name = '<AML WORKSPACE NAME>'\n",
    "dataset_name = '<LABELED DATASET NAME>'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe(FileHandlingOption.DOWNLOAD, target_path='/tmp', overwrite_download=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prep images and format tags for Custom Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we format the labels from our Azure ML labeled dataset into regions that can be uploaded to the Custom Vision service with their corresponding images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new tag for: building\n",
      "Creating new tag for: vehicle\n"
     ]
    }
   ],
   "source": [
    "tagged_ims = []\n",
    "tags = trainer.get_tags(project.id)\n",
    "\n",
    "for i, img in df.iterrows():\n",
    "    filename = img['image_url']\n",
    "    labels = img['label']\n",
    "    regions = []\n",
    "    \n",
    "    # parse labels\n",
    "    for label in labels:\n",
    "        label_name = label['label']\n",
    "\n",
    "        l = label['topX']\n",
    "        t = label['topY']\n",
    "        r = label['bottomX']\n",
    "        b = label['bottomY']\n",
    "\n",
    "        w = r-l\n",
    "        h = b-t\n",
    "        \n",
    "        # retrieve tag object by label name\n",
    "        try:\n",
    "            index = [x.name for x in tags].index(label_name)\n",
    "            tag = tags[index]\n",
    "        # create tag if it does not exist yet\n",
    "        except:\n",
    "            print(\"Creating new tag for:\", label_name)\n",
    "            tag = trainer.create_tag(project.id, label_name)\n",
    "            tags = trainer.get_tags(project.id)\n",
    "\n",
    "        # create bounding box regions\n",
    "        regions.append(Region(tag_id=tag.id,left=l,top=t,width=w,height=h))\n",
    "\n",
    "        with open(filename, mode=\"rb\") as im_data:\n",
    "            tagged_ims.append(ImageFileCreateEntry(name=filename, contents=im_data.read(), regions=regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload images and tags to Custom Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload images and labels in batches of 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading images and tags\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading images and tags\")\n",
    "for i in range(0, len(tagged_ims), 64):   \n",
    "    batch = tagged_ims[i:i+64]\n",
    "    trainer.create_images_from_files(project.id, images=batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
